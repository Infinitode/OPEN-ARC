{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8204,"sourceType":"datasetVersion","datasetId":4458}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **OPEN-ARC**\n---\n\n### Project 4: Red Wine Quality Classification Model:\n**Challenge:** Create an AI model, capable of classifying the quality of red wine.\n\n\n### Terms and Use:\nLearn more about the project's [LICENSE](https://github.com/Infinitode/OPEN-ARC/blob/main/LICENSE) and read our [CODE_OF_CONDUCT](https://github.com/Infinitode/OPEN-ARC/blob/main/CODE_OF_CONDUCT) before contributing to the project. You can contribute to this project from here: [https://github.com/Infinitode/OPEN-ARC/](https://github.com/Infinitode/OPEN-ARC/).\n\n---","metadata":{}},{"cell_type":"markdown","source":"Please fill out this performance sheet to help others quickly see your model's performance **(optional)**:\n\n### Performance Sheet:\n| Contributor | Architecture Type | Platform | Base Model | Dataset | Accuracy | Link |\n|-------------|-------------------|----------|------------|---------|----------|------|\n| Infinitode  | GradientBoostingClassifier  | Kaggle   | ✗  | Red Wine Quality | 72.8%    | [Notebook](https://github.com/Infinitode/OPEN-ARC/Project-4-RWQC/project-4-rwqc.ipynb) |\n| Username  | Unknown  | Kaggle   | ✗/✔  | Red Wine Quality | Score    | [Notebook](https://github.com) |\n\n---","metadata":{}},{"cell_type":"markdown","source":"### Model: Decision Tree Classifier:\nThis model uses **Grid Search** to optimize the model for the best performance and accuracy score while training. Grid Search uses a defined `grid` so to speak, to tune the model's parameters. Whichever combination of parameters in the grid has the highest accuracy score is used.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Load the dataset\ndata = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\n\nX = data.drop('quality', axis=1)\ny = data['quality']\n\n# Scale the numerical features to improve the accuracy score\nnumerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\nscaler = MinMaxScaler()\nX[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Tune the decision tree model using GridSearchCV\nparam_grid = {\n    'max_depth': [3, 5, 7, None],\n    'min_samples_leaf': [1, 2, 4],\n    'criterion': ['gini', 'entropy']\n}\n\ndt_grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5, scoring='accuracy')\ndt_grid_search.fit(X_train, y_train)\n\nbest_params = dt_grid_search.best_params_\nbest_dt_model = dt_grid_search.best_estimator_\n\n# Evaluate the best decision tree model on the test set\ny_pred = best_dt_model.predict(X_test)\ntest_acc = accuracy_score(y_test, y_pred)\nprint(f\"Decision Tree Test Accuracy: {test_acc}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-16T07:57:55.529226Z","iopub.execute_input":"2024-07-16T07:57:55.529628Z","iopub.status.idle":"2024-07-16T07:57:57.961108Z","shell.execute_reply.started":"2024-07-16T07:57:55.529592Z","shell.execute_reply":"2024-07-16T07:57:57.959971Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Decision Tree Test Accuracy: 0.584375\n","output_type":"stream"}]},{"cell_type":"markdown","source":"58.4% as a testing accuracy score is not great, but quite okay to serve as a starting point in our case.","metadata":{}},{"cell_type":"markdown","source":"### Model: Gradient Boosting Classifier:\nThis code preprocesses our data (removes outliers, and scales the data), performs `GridSearch` on the model, optimizing it for the best performance on the data, and also defines some testing code you can use to try out the model.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import accuracy_score\n\n# Load the dataset\ndata = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\n\ndef remove_outliers(df):\n    Q1 = df.quantile(0.25)\n    Q3 = df.quantile(0.75)\n    IQR = Q3 - Q1\n    return df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\n\n# Remove outliers from the dataset\ndata_cleaned = remove_outliers(data)\n\nprint(f\"Original dataset shape: {data.shape}\")\nprint(f\"Cleaned dataset shape: {data_cleaned.shape}\")\n\nX = data_cleaned.drop('quality', axis=1)\ny = data_cleaned['quality']\n\n# Identify numerical columns for scaling\nnumerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and fit the scaler on the training data\nscaler = MinMaxScaler()\nX_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\nX_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n\n# Create the model\ngb_model = GradientBoostingClassifier(random_state=42)\n\n# Define the parameter grid\nparam_grid = {\n    'n_estimators': [200],\n    'learning_rate': [0.01],\n    'max_depth': [15],\n    'min_samples_split': [2],\n    'min_samples_leaf': [8]\n}\n\n# Perform Grid Search with Cross-Validation\ngrid_search = GridSearchCV(estimator=gb_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\ngrid_search.fit(X_train, y_train)\n\n# Get the best parameters and model\nbest_params = grid_search.best_params_\nbest_model = grid_search.best_estimator_\n\n# Evaluate the model on the test set\ny_pred = best_model.predict(X_test)\ntest_acc = accuracy_score(y_test, y_pred)\nprint(f\"Gradient Boosting Test Accuracy: {test_acc}\")\nprint(f\"Best Parameters: {best_params}\")\n\n# Function to take user input and predict the quality of red wine\ndef predict_red_wine_quality():\n    input_data = {}\n    for feature in X.columns:\n        if feature == \"fixed acidity\":\n            print(\"Typically ranges from 4.6 to 15.9\")\n        if feature == \"volatile acidity\":\n            print(\"Typically ranges from 0.12 to 1.58\")\n        if feature == \"citric acid\":\n            print(\"Typically ranges from 0.00 to 1.00\")\n        if feature == \"residual sugar\":\n            print(\"Typically ranges from 0.9 to 15.5\")\n        if feature == \"chlorides\":\n            print(\"Typically ranges from 0.01 to 0.61\")\n        if feature == \"free sulfur dioxide\":\n            print(\"Typically ranges from 1 to 72\")\n        if feature == \"total sulfur dioxide\":\n            print(\"Typically ranges from 6 to 289\")\n        if feature == \"density\":\n            print(\"Typically ranges from 0.9900 to 1. (Compared to the density of water)\")\n        if feature == \"pH\":\n            print(\"Typically ranges from 2.74 to 4.01\")\n        if feature == \"sulphates\":\n            print(\"Typically ranges from 0.33 to 2\")\n        if feature == \"alcohol\":\n            print(\"Typically ranges from 8.4 to 14.9 (% alcohol)\")\n        value = input(f\"Enter the value for '{feature}': \")\n\n        input_data[feature] = [float(value) if feature in numerical_cols else value]\n\n    input_df = pd.DataFrame(input_data)\n\n    # Scale the input data\n    input_df[numerical_cols] = scaler.transform(input_df[numerical_cols])\n\n    # Make prediction\n    prediction = best_model.predict(input_df)\n    print(f\"Predicted quality of wine: {prediction[0]}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-16T09:13:07.311597Z","iopub.execute_input":"2024-07-16T09:13:07.312004Z","iopub.status.idle":"2024-07-16T09:13:30.406233Z","shell.execute_reply.started":"2024-07-16T09:13:07.311973Z","shell.execute_reply":"2024-07-16T09:13:30.404929Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Original dataset shape: (1599, 12)\nCleaned dataset shape: (1179, 12)\nGradient Boosting Test Accuracy: 0.7288135593220338\nBest Parameters: {'learning_rate': 0.01, 'max_depth': 15, 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 200}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Even while removing outliers from the data, the model still does not reach the ideal accuracy (only 72.8%). You can try different model architectures or preprocessing steps to achieve better results.","metadata":{}},{"cell_type":"code","source":"# Call the prediction function to test out the model\npredict_red_wine_quality()\n\n# Sample from the dataset:\n# 7.5, 0.52, 0.16, 1.9, 0.085, 12, 35, 0.9968, 3.38, 0.62, 9.5 => 7","metadata":{"execution":{"iopub.status.busy":"2024-07-16T09:08:49.461149Z","iopub.execute_input":"2024-07-16T09:08:49.461565Z","iopub.status.idle":"2024-07-16T09:09:25.916092Z","shell.execute_reply.started":"2024-07-16T09:08:49.461536Z","shell.execute_reply":"2024-07-16T09:09:25.914940Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Typically ranges from 4.6 to 15.9\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the value for 'fixed acidity':  7.5\n"},{"name":"stdout","text":"Typically ranges from 0.12 to 1.58\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the value for 'volatile acidity':  0.52\n"},{"name":"stdout","text":"Typically ranges from 0.00 to 1.00\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the value for 'citric acid':  0.16\n"},{"name":"stdout","text":"Typically ranges from 0.9 to 15.5\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the value for 'residual sugar':  1.9\n"},{"name":"stdout","text":"Typically ranges from 0.01 to 0.61\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the value for 'chlorides':  0.085\n"},{"name":"stdout","text":"Typically ranges from 1 to 72\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the value for 'free sulfur dioxide':  12\n"},{"name":"stdout","text":"Typically ranges from 6 to 289\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the value for 'total sulfur dioxide':  35\n"},{"name":"stdout","text":"Typically ranges from 0.9900 to 1. (Compared to the density of water)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the value for 'density':  0.9968\n"},{"name":"stdout","text":"Typically ranges from 2.74 to 4.01\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the value for 'pH':  3.38\n"},{"name":"stdout","text":"Typically ranges from 0.33 to 2\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the value for 'sulphates':  0.62\n"},{"name":"stdout","text":"Typically ranges from 8.4 to 14.9 (% alcohol)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the value for 'alcohol':  9.5\n"},{"name":"stdout","text":"Predicted quality of wine: 5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### The End:\nThis is the end of this project notebook, make sure to experiment and contribute to help improve the model and implementation. You can browse more of the open-source free projects on our GitHub repository: [https://github.com/Infinitode/OPEN-ARC](https://github.com/Infinitode/OPEN-ARC). If you like this project, make sure to star the repo and contribute your implementation, or help others in the community.\n\n~ Infinitode","metadata":{}}]}